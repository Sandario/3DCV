{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 03: Lukas Kanade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we implement the Lucas-Kanade algorithm for estimating optical flow between two consecutive image frames. The goal is to track how points move from one image to the next using image gradients and the structure tensor as introduced in the lecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    !pip install opencv-python\n",
    "    import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.signal import convolve2d as conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code import getM, getq, getHarrisCorners, getFlow, drawPoints, getGradients, getTemporalPartialDerivative, getGaussiankernel\n",
    "from tests import test_flow_absolute, test_flow_angular, test_flow_computation_time, test_flow_endpoint, test_gradients, test_getM,  test_getGaussiankernel, test_getHarrisCorners\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget the optical flow dataset\n",
    "import os\n",
    "\n",
    "dataset_path = '../datasets/exercise_03'\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "if not os.path.exists(dataset_path+'/other-color-allframes.zip'):\n",
    "    !wget https://vision.middlebury.edu/flow/data/comp/zip/other-color-allframes.zip --directory-prefix={dataset_path}/\n",
    "    !unzip {dataset_path}/other-color-allframes.zip -d {dataset_path}/\n",
    "\n",
    "    !wget https://vision.middlebury.edu/flow/data/comp/zip/other-gt-flow.zip --directory-prefix={dataset_path}/\n",
    "    !unzip {dataset_path}/other-gt-flow.zip -d {dataset_path}/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original image\n",
    "im1 = Image.open(dataset_path+'/other-data/RubberWhale/frame10.png')\n",
    "im1 = np.array(im1)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.axis('off')\n",
    "plt.imshow(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part I: Structure Tensor\n",
    "\n",
    "In order to be able to detect corners in an image and compute optical flow, the structure tensor $M$ shall be computed in this exercise.\n",
    "\n",
    "At first compute the image gradients $I_x$ and $I_y$ using central differences.\n",
    "- Go to ```getGradients``` in ```exercise_code/utils.py``` and fill in the missing lines of code.\n",
    "\n",
    "For visual intuition on the image gradient, we provide two examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an image of a white circle on black background to check the computet gradients\n",
    "H, W = 100, 100\n",
    "im1 = np.zeros((H, W), dtype=np.uint8)\n",
    "center = (W // 2, H // 2)\n",
    "radius = 30\n",
    "\n",
    "Y, X = np.ogrid[:H, :W]\n",
    "mask = (X - center[0])**2 + (Y - center[1])**2 <= radius**2\n",
    "im1[mask] = 10\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.axis('off')\n",
    "plt.imshow(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image gradients\n",
    "Ix, Iy = getGradients(im1, sigma=2) #No smoothing\n",
    "\n",
    "# show image gradients\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Ix, cmap='gray')\n",
    "plt.title('$I_x$')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Iy, cmap='gray')\n",
    "plt.title('$I_y$')\n",
    "plt.axis('off')\n",
    "# show image gradients by vector field\n",
    "plt.figure(figsize=(6,6))\n",
    "X = np.arange(0, Ix.shape[1], 1)\n",
    "Y = np.arange(0, Ix.shape[0], 1)\n",
    "\n",
    "# plot every 4th vector to avoid clutter\n",
    "d = 4\n",
    "q = plt.quiver(X[::d],Y[::d],Ix[::d,::d],-1*Iy[::d,::d])\n",
    "plt.axis('off')\n",
    "plt.title('Image Gradients as Vector Field')\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()\n",
    "\n",
    "#The gradient vector should point in the direction of largest possible intensity increase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do the same for a real sample\n",
    "im1 = Image.open(dataset_path+'/other-data/RubberWhale/frame10.png')\n",
    "# convert to grayscale\n",
    "im1 = im1.convert('L')\n",
    "im1 = np.array(im1)\n",
    "\n",
    "# get image gradients\n",
    "Ix, Iy = getGradients(im1, sigma=1)\n",
    "\n",
    "\n",
    "# show image gradients\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Ix, cmap='gray')\n",
    "plt.title('$I_x$')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Iy, cmap='gray')\n",
    "plt.title('$I_y$')\n",
    "plt.axis('off')\n",
    "# show image gradients by vector field\n",
    "plt.figure(figsize=(6,6))\n",
    "X = np.arange(0, Ix.shape[1], 1)\n",
    "Y = np.arange(0, Ix.shape[0], 1)\n",
    "\n",
    "# plot every 4th vector to avoid clutter\n",
    "d = 4\n",
    "q = plt.quiver(X[::d],Y[::d],Ix[::d,::d],-1*Iy[::d,::d])\n",
    "plt.axis('off')\n",
    "plt.title('Image Gradients as Vector Field')\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gradients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compute the structure tensor $M$ we need a two-dimensional Gaussian Kernel as a weighting function.\n",
    "\n",
    "- Compute  a two-dimensional Gaussian Kernel with a standard deviation. Use a kernel size (and hence integration window size) $k = 4\\sigma+1$. Go to ```getGaussiankernel``` in ```exercise_code/utils.py``` and fill in the missing lines of code to compute the kernel $G$.\n",
    "\n",
    "For visual intuition on the effect of applying the kernel to an example image through convolution, we provide an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3 #try different values to observe how sigma affects the smoothing/blurring effect during convolution\n",
    "G = getGaussiankernel(sigma)\n",
    "\n",
    "# gaussian blur using the computed kernel\n",
    "blurred = conv2(im1, G, 'same',  boundary='symm')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# gaussian kernel as heatmap\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(G, cmap='viridis', interpolation='nearest')\n",
    "plt.title(f'Gaussian Kernel (Ïƒ={sigma})')\n",
    "plt.axis('off')\n",
    "\n",
    "# original image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(im1, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "#blurred image\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(blurred, cmap='gray')\n",
    "plt.title('Blurred Image')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_getGaussiankernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a function that computes the entries of the structure tensor $M$ (see question 1(a) of exercise sheet 5) for every pixel $(x,y)$ of an image $I$. \n",
    "\n",
    "- Compute the structure tensor using a weighting function $G$ to compute the structure tensor $M$, i.e. a $2 \\times 2$ matrix for each Pixel.  Why is it not necessary to compute $m_{21}$? Go to ```getM``` in ```exercise_code/utils.py```and fill in the missing lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get structure tensor\n",
    "M = getM(Ix, Iy, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_getM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Corner Detection\n",
    "\n",
    "Now let us compute some intereset points which we want to track.\n",
    "In this exercise you will implement the Harris corner detector. Go to ```getHarrisCorners``` in ```exercise_code/getHarrisCorners.py``` and fill in the missing lines of code using the following method:\n",
    "\n",
    "- Compute the scoring function $C := \\text{det}(M) - \\kappa \\text{ trace}^2(M)$ for each pixel $(x,y)$.\n",
    "- Find all pixels $(x,y)$ for which $C(x,y) > \\theta$, and which are a local maximum of the scoring function, i.e. all four adjacent pixel have a lower score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.05 # k for Harris corner detection\n",
    "t = 1e-6 # threshold for Harris corner detection\n",
    "\n",
    "score, points = getHarrisCorners(M, k, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "im1_ = drawPoints(im1.copy(), points[:, [1, 0]].T)\n",
    "plt.imshow(im1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_getHarrisCorners()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Optical Flow\n",
    "\n",
    "In this exercise you will implement the Lucas-Kanade method to compute optical flow.\n",
    "But first check the ground truth data as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a gif of the two images\n",
    "im1 = Image.open(dataset_path+'/other-data/RubberWhale/frame10.png')\n",
    "im2 = Image.open(dataset_path+'/other-data/RubberWhale/frame11.png')\n",
    "# overwrite the gif file\n",
    "\n",
    "im1.save(dataset_path+'/img.gif', save_all=True, append_images=[im2], duration=1000, loop=0)\n",
    "# show the gif\n",
    "from IPython.display import Image as IPImage\n",
    "IPImage(filename=dataset_path+'/img.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = cv2.readOpticalFlow(dataset_path+'/other-gt-flow/RubberWhale/flow10.flo')\n",
    "\n",
    "mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "mag[mag>2357022699]=0\n",
    "hsv = np.zeros_like(im1)\n",
    "hsv[..., 0] = ang*180/np.pi/2\n",
    "hsv[..., 1] = 255\n",
    "hsv[..., 2] = 255\n",
    "hsv[..., 2] = cv2.normalize(mag, None, 100, 255, cv2.NORM_MINMAX)\n",
    "bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(bgr)\n",
    "plt.axis('off')\n",
    "plt.title('Ground Truth Optical Flow')\n",
    "plt.subplot(1, 2, 2)\n",
    "# read the image\n",
    "im_hsv = Image.open('hsv.jpg')\n",
    "plt.axis('off')\n",
    "plt.imshow(im_hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1_gray = im1.convert('L')\n",
    "im2_gray = im2.convert('L')\n",
    "\n",
    "im1_gray = np.array(im1_gray)\n",
    "im2_gray = np.array(im2_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV Lukas Kanade Implementation\n",
    "\n",
    "As a reference you can checkout the openCV implementation of the Lukas Kanade optical flow.\n",
    "You can already see that it can capture the direction of movement quite accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dense points for flow\n",
    "x = np.arange(0, im1_gray.shape[0], 1)\n",
    "y = np.arange(0, im1_gray.shape[1], 1)\n",
    "x, y = np.meshgrid(x, y)\n",
    "p0 = np.array([y.flatten(), x.flatten()]).T # opencv uses different order\n",
    "p0 = p0[:,None,:].astype(np.float32)\n",
    "lk_params = dict( winSize = (15, 15),\n",
    " maxLevel = 0,\n",
    " criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(im1_gray, im2_gray, p0, None, **lk_params)\n",
    "\n",
    "# Select good points\n",
    "good_new = p1[st==1]\n",
    "good_old = p0[st==1]\n",
    "\n",
    "flow_lk = np.zeros((im1_gray.shape[0], im1_gray.shape[1], 2))\n",
    "# fill in the flow\n",
    "for i in range(len(good_new)):\n",
    "    try:\n",
    "        flow_lk[int(good_old[i][1]), int(good_old[i][0])] = good_new[i] - good_old[i] # opencv uses different order\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag, ang = cv2.cartToPolar(flow_lk[...,0], flow_lk[...,1])\n",
    "hsv = np.zeros_like(im1)\n",
    "hsv[..., 0] = ang*180/np.pi/2\n",
    "hsv[..., 1] = 255\n",
    "hsv[..., 2] = 255\n",
    "hsv[..., 2] = cv2.normalize(mag, None, 100, 255, cv2.NORM_MINMAX)\n",
    "bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(bgr)\n",
    "plt.axis('off')\n",
    "plt.title('Lukas Kanade Optical Flow')\n",
    "plt.subplot(1, 2, 2)\n",
    "# read the image\n",
    "im_hsv = Image.open('hsv.jpg')\n",
    "plt.axis('off')\n",
    "plt.imshow(im_hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Lukas Kanade implementation\n",
    "Now let's start with our own implementation:\n",
    "- Write a function that computes the vector $I_t$ for every pixel $(x,y)$. Go to ```getTemporalPartialDerivative``` in ```exercise_code/utils.py```and fill in the missing lines of code.\n",
    "- Write a function that computes the vector $\\mathbf{q}$ for every pixel $(x,y)$. Go to ```getq``` in ```exercise_code/utils.py```and fill in the missing lines of code.\n",
    "- Write a function that computes the local velocity $(\\hat{v}_x,\\hat{v}_y)$ at the input points using the formula derived in theory. Go to ```getFlow``` in ```exercise_code/getFlow.py```and fill in the missing lines of code.\n",
    "- Try different values for $\\sigma$. What do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_gradient = 1\n",
    "sigma = 7\n",
    "It = getTemporalPartialDerivative(im1_gray, im2_gray, sigma=sigma_gradient)\n",
    "Ix, Iy = getGradients(im1_gray, sigma=sigma_gradient)\n",
    "q = getq(It, Ix, Iy, sigma=sigma)\n",
    "print(q.shape)\n",
    "M = getM(Ix, Iy, sigma=sigma)\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compute the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dense points for flow\n",
    "x = np.arange(0, im1_gray.shape[0], 1)\n",
    "y = np.arange(0, im1_gray.shape[1], 1)\n",
    "x, y = np.meshgrid(x, y)\n",
    "points = np.array([x.flatten(), y.flatten()]).T\n",
    "flow_lk,flow_lk_points = getFlow(M, q, points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag, ang = cv2.cartToPolar(flow_lk[...,0], flow_lk[...,1])\n",
    "hsv = np.zeros_like(im1)\n",
    "hsv[..., 0] = ang*180/np.pi/2\n",
    "hsv[..., 1] = 255\n",
    "hsv[..., 2] = 255\n",
    "hsv[..., 2] = cv2.normalize(mag, None, 100, 255, cv2.NORM_MINMAX)\n",
    "bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(bgr)\n",
    "plt.axis('off')\n",
    "plt.title('Lukas Kanade Optical Flow')\n",
    "plt.subplot(1, 2, 2)\n",
    "# read the image\n",
    "im_hsv = Image.open('hsv.jpg')\n",
    "plt.axis('off')\n",
    "plt.imshow(im_hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your method\n",
    "Here, you can test your method locally. If you want to compare your method to the implementations of other students, you can submit the code on the test server.\n",
    "There will be a leaderboard showing the best optical flow algorithm on the top.\n",
    "For the final submission, please set the default values in your function already.\n",
    "We will not pass any parameters (like $\\sigma$) for evaluation.\n",
    "\n",
    "If you want to checkout the worldwide leaderboard, you can follow this link:\n",
    "[Middlebury Evaluation](https://vision.middlebury.edu/flow/eval/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = test_flow_angular(dataset_path) # cosine similarity of normalized vectors [-1,1] (the higher the better)\n",
    "score = test_flow_absolute(dataset_path) # mse of vector length [0, inf] (the lower the better)\n",
    "score = test_flow_computation_time(dataset_path) # time in seconds [0, inf] (the lower the better)\n",
    "score = test_flow_endpoint(dataset_path) # mse of endpoint [0, inf] (the lower the better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results obtained from the opencv implementation of the highly optimized OpenCV Lukas Kanade Tracker as a reference.\n",
    "\n",
    "\n",
    "![](opencv_eval.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.submit import submit_exercise\n",
    "\n",
    "submit_exercise('../output/exercise03')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2mvg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
